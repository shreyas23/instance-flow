{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1cb6c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "12f0f6a6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "[torch.Size([1, 64, 128, 416]),\n",
      " torch.Size([1, 128, 64, 208]),\n",
      " torch.Size([1, 256, 32, 104]),\n",
      " torch.Size([1, 512, 16, 52])]\n"
     ]
    }
   ],
   "source": [
    "%autoreload\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "from pprint import pprint\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.autograd import Variable\n",
    "from mmdet.models.backbones import ResNet\n",
    "from mmdet.models.flow_heads import FlowHead\n",
    "from torchvision.transforms.functional import resize\n",
    "from spatial_correlation_sampler import SpatialCorrelationSampler\n",
    "\n",
    "# test image\n",
    "img0 = Image.open('/external/datasets/kitti/2015/training/image_2/000000_10.png')\n",
    "img0 = np.asarray(resize(img0, (256, 832)))\n",
    "img0 = torch.from_numpy(img0).permute(2, 0, 1).unsqueeze(0).cuda() / 255. \n",
    "\n",
    "img1 = Image.open('/external/datasets/kitti/2015/training/image_2/000000_11.png')\n",
    "img1 = np.asarray(resize(img1, (256, 832)))\n",
    "img1 = torch.from_numpy(img1).permute(2, 0, 1).unsqueeze(0).cuda() / 255. \n",
    "\n",
    "backbone = ResNet(depth=18).cuda()\n",
    "print(backbone)\n",
    "features0 = [f.contiguous() for f in backbone(img0)]\n",
    "features1 = [f.contiguous() for f in backbone(img1)]\n",
    "pprint([f.shape for f in features0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "25875e9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 512, 16, 52]) torch.Size([1, 256, 32, 104]) torch.Size([1, 128, 64, 208]) torch.Size([1, 64, 128, 416])\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'asdf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [30]\u001b[0m, in \u001b[0;36m<cell line: 231>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    229\u001b[0m imgs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([img0, img1], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    230\u001b[0m flow_head \u001b[38;5;241m=\u001b[39m FlowHead()\u001b[38;5;241m.\u001b[39mcuda()\n\u001b[0;32m--> 231\u001b[0m outs \u001b[38;5;241m=\u001b[39m \u001b[43mflow_head\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimgs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeatures0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeatures1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28mprint\u001b[39m(outs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[0;32m~/envs/vif/lib/python3.8/site-packages/torch/nn/modules/module.py:550\u001b[0m, in \u001b[0;36mModule.__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_slow_forward(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    549\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 550\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    551\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks\u001b[38;5;241m.\u001b[39mvalues():\n\u001b[1;32m    552\u001b[0m     hook_result \u001b[38;5;241m=\u001b[39m hook(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, result)\n",
      "Input \u001b[0;32mIn [30]\u001b[0m, in \u001b[0;36mFlowHead.forward\u001b[0;34m(self, x, feats0, feats1)\u001b[0m\n\u001b[1;32m    164\u001b[0m c21, c22, c23, c24 \u001b[38;5;241m=\u001b[39m feats1\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28mprint\u001b[39m(c14\u001b[38;5;241m.\u001b[39mshape, c13\u001b[38;5;241m.\u001b[39mshape, c12\u001b[38;5;241m.\u001b[39mshape, c11\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m--> 167\u001b[0m \u001b[43masdf\u001b[49m\n\u001b[1;32m    169\u001b[0m corr4 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcorr(c14, c24)  \n\u001b[1;32m    170\u001b[0m b, pw, ph, w, h \u001b[38;5;241m=\u001b[39m corr4\u001b[38;5;241m.\u001b[39mshape\n",
      "\u001b[0;31mNameError\u001b[0m: name 'asdf' is not defined"
     ]
    }
   ],
   "source": [
    "def conv(in_planes, out_planes, kernel_size=3, stride=1, padding=1, dilation=1):   \n",
    "    return nn.Sequential(\n",
    "            nn.Conv2d(in_planes, out_planes, kernel_size=kernel_size, stride=stride, \n",
    "                        padding=padding, dilation=dilation, bias=True),\n",
    "            nn.LeakyReLU(0.1))\n",
    "\n",
    "def predict_flow(in_planes):\n",
    "    return nn.Conv2d(in_planes,2,kernel_size=3,stride=1,padding=1,bias=True)\n",
    "\n",
    "def deconv(in_planes, out_planes, kernel_size=4, stride=2, padding=1):\n",
    "    return nn.ConvTranspose2d(in_planes, out_planes, kernel_size, stride, padding, bias=True)\n",
    "\n",
    "class FlowHead(nn.Module):\n",
    "    \"\"\"\n",
    "        PWC-DC net. add dilation convolution and densenet connections\n",
    "    \"\"\"\n",
    "    def __init__(self, md=4):\n",
    "        \"\"\"\n",
    "        input: md --- maximum displacement (for correlation. default: 4), after warping\n",
    "\n",
    "        \"\"\"\n",
    "        super(FlowHead,self).__init__()\n",
    "        \n",
    "#         self.conv1a  = conv(3,   16, kernel_size=3, stride=2)\n",
    "#         self.conv1aa = conv(16,  16, kernel_size=3, stride=1)\n",
    "#         self.conv1b  = conv(16,  16, kernel_size=3, stride=1)\n",
    "\n",
    "#         self.conv2a  = conv(16,  32, kernel_size=3, stride=2)\n",
    "#         self.conv2aa = conv(32,  32, kernel_size=3, stride=1)\n",
    "#         self.conv2b  = conv(32,  32, kernel_size=3, stride=1)\n",
    "\n",
    "#         self.conv3a  = conv(32,  64, kernel_size=3, stride=2)\n",
    "#         self.conv3aa = conv(64,  64, kernel_size=3, stride=1)\n",
    "#         self.conv3b  = conv(64,  64, kernel_size=3, stride=1)\n",
    "\n",
    "#         self.conv4a  = conv(64,  96, kernel_size=3, stride=2)\n",
    "#         self.conv4aa = conv(96,  96, kernel_size=3, stride=1)\n",
    "#         self.conv4b  = conv(96,  96, kernel_size=3, stride=1)\n",
    "\n",
    "#         self.conv5a  = conv(96, 128, kernel_size=3, stride=2)\n",
    "#         self.conv5aa = conv(128,128, kernel_size=3, stride=1)\n",
    "#         self.conv5b  = conv(128,128, kernel_size=3, stride=1)\n",
    "\n",
    "#         self.conv6aa = conv(128,196, kernel_size=3, stride=2)\n",
    "#         self.conv6a  = conv(196,196, kernel_size=3, stride=1)\n",
    "#         self.conv6b  = conv(196,196, kernel_size=3, stride=1)\n",
    "\n",
    "        # Original NVIDIA correlation module\n",
    "        # self.corr    = Correlation(pad_size=md, kernel_size=1, max_displacement=md, stride1=1, stride2=1, corr_multiply=1)\n",
    "        self.corr    = SpatialCorrelationSampler(kernel_size=1, patch_size=(2*md + 1), stride=1, padding=0, dilation=1, dilation_patch=1)\n",
    "        self.leakyRELU = nn.LeakyReLU(0.1)\n",
    "        \n",
    "        nd = (2*md+1)**2\n",
    "        dd = np.cumsum([128,128,96,64,32])\n",
    "\n",
    "#         od = nd\n",
    "#         self.conv6_0 = conv(od,      128, kernel_size=3, stride=1)\n",
    "#         self.conv6_1 = conv(od+dd[0],128, kernel_size=3, stride=1)\n",
    "#         self.conv6_2 = conv(od+dd[1],96,  kernel_size=3, stride=1)\n",
    "#         self.conv6_3 = conv(od+dd[2],64,  kernel_size=3, stride=1)\n",
    "#         self.conv6_4 = conv(od+dd[3],32,  kernel_size=3, stride=1)        \n",
    "#         self.predict_flow6 = predict_flow(od+dd[4])\n",
    "#         self.deconv6 = deconv(2, 2, kernel_size=4, stride=2, padding=1) \n",
    "#         self.upfeat6 = deconv(od+dd[4], 2, kernel_size=4, stride=2, padding=1) \n",
    "\n",
    "#         od = nd+128+4\n",
    "#         self.conv5_0 = conv(od,      128, kernel_size=3, stride=1)\n",
    "#         self.conv5_1 = conv(od+dd[0],128, kernel_size=3, stride=1)\n",
    "#         self.conv5_2 = conv(od+dd[1],96,  kernel_size=3, stride=1)\n",
    "#         self.conv5_3 = conv(od+dd[2],64,  kernel_size=3, stride=1)\n",
    "#         self.conv5_4 = conv(od+dd[3],32,  kernel_size=3, stride=1)\n",
    "#         self.predict_flow5 = predict_flow(od+dd[4]) \n",
    "#         self.deconv5 = deconv(2, 2, kernel_size=4, stride=2, padding=1) \n",
    "#         self.upfeat5 = deconv(od+dd[4], 2, kernel_size=4, stride=2, padding=1) \n",
    "        \n",
    "        od = nd\n",
    "        self.conv4_0 = conv(od,      128, kernel_size=3, stride=1)\n",
    "        self.conv4_1 = conv(od+dd[0],128, kernel_size=3, stride=1)\n",
    "        self.conv4_2 = conv(od+dd[1],96,  kernel_size=3, stride=1)\n",
    "        self.conv4_3 = conv(od+dd[2],64,  kernel_size=3, stride=1)\n",
    "        self.conv4_4 = conv(od+dd[3],32,  kernel_size=3, stride=1)\n",
    "        self.predict_flow4 = predict_flow(od+dd[4]) \n",
    "        self.deconv4 = deconv(2, 2, kernel_size=4, stride=2, padding=1) \n",
    "        self.upfeat4 = deconv(od+dd[4], 2, kernel_size=4, stride=2, padding=1) \n",
    "        \n",
    "        od = nd+256+4\n",
    "        self.conv3_0 = conv(od,      128, kernel_size=3, stride=1)\n",
    "        self.conv3_1 = conv(od+dd[0],128, kernel_size=3, stride=1)\n",
    "        self.conv3_2 = conv(od+dd[1],96,  kernel_size=3, stride=1)\n",
    "        self.conv3_3 = conv(od+dd[2],64,  kernel_size=3, stride=1)\n",
    "        self.conv3_4 = conv(od+dd[3],32,  kernel_size=3, stride=1)\n",
    "        self.predict_flow3 = predict_flow(od+dd[4]) \n",
    "        self.deconv3 = deconv(2, 2, kernel_size=4, stride=2, padding=1) \n",
    "        self.upfeat3 = deconv(od+dd[4], 2, kernel_size=4, stride=2, padding=1) \n",
    "        \n",
    "        od = nd+128+4\n",
    "        self.conv2_0 = conv(od,      128, kernel_size=3, stride=1)\n",
    "        self.conv2_1 = conv(od+dd[0],128, kernel_size=3, stride=1)\n",
    "        self.conv2_2 = conv(od+dd[1],96,  kernel_size=3, stride=1)\n",
    "        self.conv2_3 = conv(od+dd[2],64,  kernel_size=3, stride=1)\n",
    "        self.conv2_4 = conv(od+dd[3],32,  kernel_size=3, stride=1)\n",
    "        self.predict_flow2 = predict_flow(od+dd[4]) \n",
    "        self.deconv2 = deconv(2, 2, kernel_size=4, stride=2, padding=1) \n",
    "        # TODO: THIS IS WHERE I AM AND IM INTEGRATING C11 INTO THE MODULE\n",
    "        self.upfeat2 = deconv(od+dd[4], 2, kernel_size=4, stride=2, padding=1) \n",
    "        \n",
    "        self.dc_conv1 = conv(od+dd[4], 128, kernel_size=3, stride=1, padding=1,  dilation=1)\n",
    "        self.dc_conv2 = conv(128,      128, kernel_size=3, stride=1, padding=2,  dilation=2)\n",
    "        self.dc_conv3 = conv(128,      128, kernel_size=3, stride=1, padding=4,  dilation=4)\n",
    "        self.dc_conv4 = conv(128,      96,  kernel_size=3, stride=1, padding=8,  dilation=8)\n",
    "        self.dc_conv5 = conv(96,       64,  kernel_size=3, stride=1, padding=16, dilation=16)\n",
    "        self.dc_conv6 = conv(64,       32,  kernel_size=3, stride=1, padding=1,  dilation=1)\n",
    "        self.dc_conv7 = predict_flow(32)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d):\n",
    "                nn.init.kaiming_normal_(m.weight.data, mode='fan_in')\n",
    "                if m.bias is not None:\n",
    "                    m.bias.data.zero_()\n",
    "\n",
    "\n",
    "    def warp(self, x, flo):\n",
    "        \"\"\"\n",
    "        warp an image/tensor (im2) back to im1, according to the optical flow\n",
    "\n",
    "        x: [B, C, H, W] (im2)\n",
    "        flo: [B, 2, H, W] flow\n",
    "\n",
    "        \"\"\"\n",
    "        B, C, H, W = x.size()\n",
    "        # mesh grid \n",
    "        xx = torch.arange(0, W).view(1,-1).repeat(H,1)\n",
    "        yy = torch.arange(0, H).view(-1,1).repeat(1,W)\n",
    "        xx = xx.view(1,1,H,W).repeat(B,1,1,1)\n",
    "        yy = yy.view(1,1,H,W).repeat(B,1,1,1)\n",
    "        grid = torch.cat((xx,yy),1).float()\n",
    "\n",
    "        if x.is_cuda:\n",
    "            grid = grid.cuda()\n",
    "        vgrid = Variable(grid) + flo\n",
    "\n",
    "        # scale grid to [-1,1] \n",
    "        vgrid[:,0,:,:] = 2.0*vgrid[:,0,:,:].clone() / max(W-1,1)-1.0\n",
    "        vgrid[:,1,:,:] = 2.0*vgrid[:,1,:,:].clone() / max(H-1,1)-1.0\n",
    "\n",
    "        vgrid = vgrid.permute(0,2,3,1)        \n",
    "        output = nn.functional.grid_sample(x, vgrid)\n",
    "        mask = torch.autograd.Variable(torch.ones(x.size())).cuda()\n",
    "        mask = nn.functional.grid_sample(mask, vgrid)\n",
    "\n",
    "        # if W==128:\n",
    "            # np.save('mask.npy', mask.cpu().data.numpy())\n",
    "            # np.save('warp.npy', output.cpu().data.numpy())\n",
    "        \n",
    "        mask[mask<0.9999] = 0\n",
    "        mask[mask>0] = 1\n",
    "        \n",
    "        return output*mask\n",
    "\n",
    "\n",
    "    def forward(self,x, feats0=None, feats1=None):\n",
    "        im1 = x[:,:3,:,:]\n",
    "        im2 = x[:,3:,:,:]\n",
    "        \n",
    "        c11, c12, c13, c14 = feats0\n",
    "        c21, c22, c23, c24 = feats1\n",
    "\n",
    "\n",
    "        corr4 = self.corr(c14, c24)  \n",
    "        b, pw, ph, w, h = corr4.shape\n",
    "        corr4 = corr4.reshape(b, pw*ph, w, h)\n",
    "        corr4 = self.leakyRELU(corr4)\n",
    "        x = torch.cat((self.conv4_0(corr4), corr4), 1)\n",
    "        x = torch.cat((self.conv4_1(x), x),1)\n",
    "        x = torch.cat((self.conv4_2(x), x),1)\n",
    "        x = torch.cat((self.conv4_3(x), x),1)\n",
    "        x = torch.cat((self.conv4_4(x), x),1)\n",
    "        flow4 = self.predict_flow4(x)\n",
    "        up_flow4 = self.deconv4(flow4)\n",
    "        up_feat4 = self.upfeat4(x)\n",
    "\n",
    "\n",
    "        warp3 = self.warp(c23, up_flow4*2.5)\n",
    "        corr3 = self.corr(c13, warp3) \n",
    "        b, pw, ph, w, h = corr3.shape\n",
    "        corr3 = corr3.reshape(b, pw*ph, w, h)\n",
    "        corr3 = self.leakyRELU(corr3)\n",
    "\n",
    "\n",
    "        x = torch.cat((corr3, c13, up_flow4, up_feat4), 1)\n",
    "        x = torch.cat((self.conv3_0(x), x),1)\n",
    "        x = torch.cat((self.conv3_1(x), x),1)\n",
    "        x = torch.cat((self.conv3_2(x), x),1)\n",
    "        x = torch.cat((self.conv3_3(x), x),1)\n",
    "        x = torch.cat((self.conv3_4(x), x),1)\n",
    "        flow3 = self.predict_flow3(x)\n",
    "        up_flow3 = self.deconv3(flow3)\n",
    "        up_feat3 = self.upfeat3(x)\n",
    "\n",
    "\n",
    "        warp2 = self.warp(c22, up_flow3*5.0) \n",
    "        corr2 = self.corr(c12, warp2)\n",
    "        b, pw, ph, w, h = corr2.shape\n",
    "        corr2 = corr2.reshape(b, pw*ph, w, h)\n",
    "        corr2 = self.leakyRELU(corr2)\n",
    "        x = torch.cat((corr2, c12, up_flow3, up_feat3), 1)\n",
    "        x = torch.cat((self.conv2_0(x), x),1)\n",
    "        x = torch.cat((self.conv2_1(x), x),1)\n",
    "        x = torch.cat((self.conv2_2(x), x),1)\n",
    "        x = torch.cat((self.conv2_3(x), x),1)\n",
    "        x = torch.cat((self.conv2_4(x), x),1)\n",
    "        flow2 = self.predict_flow2(x)\n",
    "        up_flow2 = self.deconv2(flow2)\n",
    "        up_feat2 = self.upfeat2(x)\n",
    "        \n",
    "        \n",
    "        warp1 = self.warp(c22, up_flow3*5.0) \n",
    "        corr2 = self.corr(c12, warp2)\n",
    "        b, pw, ph, w, h = corr2.shape\n",
    "        corr2 = corr2.reshape(b, pw*ph, w, h)\n",
    "        corr2 = self.leakyRELU(corr2)\n",
    "        x = torch.cat((corr2, c12, up_flow3, up_feat3), 1)\n",
    "        x = torch.cat((self.conv2_0(x), x),1)\n",
    "        x = torch.cat((self.conv2_1(x), x),1)\n",
    "        x = torch.cat((self.conv2_2(x), x),1)\n",
    "        x = torch.cat((self.conv2_3(x), x),1)\n",
    "        x = torch.cat((self.conv2_4(x), x),1)\n",
    "        flow2 = self.predict_flow2(x)\n",
    " \n",
    "        x = self.dc_conv4(self.dc_conv3(self.dc_conv2(self.dc_conv1(x))))\n",
    "        flow2 = flow2 + self.dc_conv7(self.dc_conv6(self.dc_conv5(x)))\n",
    "        \n",
    "        if self.training:\n",
    "            return flow2,flow3,flow4\n",
    "        else:\n",
    "            return flow2\n",
    "    \n",
    "    def loss(self, pred_flow, gt_flow):\n",
    "        \"\"\"\n",
    "            Supervised loss is the dense L1-norm.\n",
    "        \"\"\"\n",
    "        loss = None\n",
    "        return loss\n",
    "\n",
    "imgs = torch.cat([img0, img1], dim=1)\n",
    "flow_head = FlowHead().cuda()\n",
    "outs = flow_head(imgs, features0, features1)\n",
    "print(outs[0].shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vif",
   "language": "python",
   "name": "vif"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
